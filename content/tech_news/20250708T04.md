---
title: "2025.07.08.04 过去4小时全球AI发生了什么？"
date: 2025-07-08T04:00:19+08:00
categories: ["AI News", "OpenAI", "Anthropic", "AI Policy", "LLMs"]
---

---

以下是过去4小时内全球AI领域的重要动态回顾：

1.  [OpenAI面临组织结构和财务可持续性质疑-Gary Marcus](https://x.com/GaryMarcus/status/1942302170591945086)

    知名人工智能研究者Gary Marcus对OpenAI的潜在组织结构调整表达了担忧。据报道，OpenAI正考虑一项方案，使其非营利实体所占公司股份不足三分之一，这意味着大部分所有权将分配给员工、微软和投资者。Gary Marcus对此举的合理性提出质疑，认为这与OpenAI最初的非营利性质相悖。他还指出，OpenAI去年的**股票薪酬支出飙升至营收的119%**，这种财务比例对于一个估值3000亿美元的公司而言是难以持续的，加剧了对其商业模式可持续性的忧虑。

2.  [LLM无法对齐的观点再次被强调-Gary Marcus](https://x.com/GaryMarcus/status/1942302875092410502)

    Gary Marcus再次重申其长期以来的观点，即**大型语言模型（LLMs）无法实现对齐（alignment）**。这一论断触及AI安全和控制领域的深层问题，挑战了当前业界对AI系统实现可靠、安全行为的普遍期望和研究方向。他的持续强调表明了对现有AI对齐方法局限性的深刻不信任，并呼吁对AI的潜在风险保持高度警惕。

3.  [Anthropic发布AI透明度框架及“系统卡”提案-Jack Clark](https://x.com/jackclarkSF/status/1942277205209555184)

    Anthropic公布了一项详细的**AI透明度框架**，旨在为强大AI系统的治理提供指导。该框架的核心提案之一是要求公司在发布模型时发布“系统卡”，其中将像超市商品的“成分清单”一样，详细记录模型的测试、评估和缓解措施。Anthropic希望此框架能在联邦、州或国际层面应用，以促进一个健康发展的AI生态系统，并推动AI治理的公开对话。

4.  [公众对Google AI概览的依赖度引关注-Peter H. Diamandis, MD](https://x.com/PeterDiamandis/status/1942289138801123835)

    Peter H. Diamandis博士发起一项民意调查，旨在了解公众在日常搜索和研究中对Google **AI概览（AI Overviews）**的依赖程度。这项调查反映出业界和公众对AI在搜索结果中扮演角色的持续关注，以及用户对其准确性、有用性的体验和信任程度。结果将为我们理解AI搜索功能的实际用户行为和接受度提供更多洞察。

5.  [Hugging Face模型现可直接在VS Code中调用-clem 🤗](https://x.com/ClementDelangue/status/1942276841403830630)

    Hugging Face的CEO Clem Delangue转发消息，强调现在用户可以通过 **Hugging Face MCP服务器**直接在Microsoft Visual Studio Code中利用最先进的AI模型。这一集成极大地方便了开发者在常用的代码编辑环境中直接访问和部署前沿AI模型，有望加速AI应用和工具的开发流程，提高开发效率。

6.  [新AI项目Smithery.AI旨在促进智能体协作-Ben Tossell](https://x.com/bentossell/status/1942265367323095154)

    Ben Tossell宣布了Smithery.AI的共同创立，这是一个新的平台，旨在支持**智能体（agents）之间的协作**。Smithery.AI的愿景是解决在单一模型无法提供所有答案的复杂场景中，不同AI模型和智能体如何协同工作的问题。该项目的启动预示着AI领域将更加注重多智能体系统和协作AI能力的开发，以应对更广泛和复杂的挑战。

7.  [Anthropic持续投入AI安全研究-clem 🤗](https://x.com/ClementDelangue/status/1942261003674124458)

    Clem Delangue还提到了**Anthropic或由Anthropic赞助的AI安全相关论文**。这表明Anthropic不仅在AI模型开发和透明度框架方面有所贡献，还在AI安全研究领域持续投入资源，推动对AI潜在风险的理解和缓解方案的探索。这进一步巩固了Anthropic在负责任AI发展方面的领先地位。