---
title: "2025.07.13.00 过去4小时全球AI发生了什么？"
date: 2025-07-13T00:00:20+08:00
categories: ["AI", "大型语言模型", "技术进展"]
---

1.  [月之暗面 Kimi 发布1万亿参数 MoE 模型 - merve](https://x.com/mervenoyann/status/1944040491697274999)

    月之暗面（**@Kimi_Moonshot**）发布了一个拥有 **1万亿参数** 的混合专家（MoE）模型，其活跃参数为 **320亿**，训练数据量高达 **15.5万亿** tokens。该模型以 **MIT许可证** 开源。值得注意的是，月之暗面的CEO是 **XLNet** 和 **TransformerXL** 这两个早期重要语言模型的第一作者，这为该模型的强大背景提供了注脚。

2.  [Gary Marcus：模型规模并非解决AI问题的唯一途径 - Gary Marcus](https://x.com/GaryMarcus/status/1944047688401793144)

    针对新发布的万亿参数模型，学者 Gary Marcus 再次强调了他长期以来的观点：**模型规模（scaling）并非万能**。他指出，当一个模型使用了巨大规模的计算资源，但在性能上却没有实现同等级别的突破时，这应该被视为给整个行业的一个“**巨大警钟**”。他认为，业界需要尽快认识到单纯依靠扩大模型规模所带来的回报正在递减。

3.  [LFM2 模型新增 GGUF 支持，可在低功耗设备运行 - clem 🤗](https://x.com/ClementDelangue/status/1944044841135923459)

    开发者 Maxime Labonne 宣布，**LFM2** 模型现已支持 **GGUF** 格式。这一更新使得像 **LFM2-350M** 这样的小型模型可以在计算资源有限的设备上（被比喻为“微波炉”）高效运行，极大地提升了模型的可及性和部署灵活性。

4.  [ICML 新论文探讨：完美预测的AI是否仍可能有糟糕的世界模型？ - Gary Marcus](https://x.com/GaryMarcus/status/1944009543941599347)

    一篇新的 **ICML** 论文被重点提及，该研究探讨了一个核心问题：一个AI模型是否可以在做出完美预测的同时，其内部的“世界模型”却非常糟糕？该论文对此问题进行了形式化分析，深入研究了模型的预测能力与其对世界真实理解之间的差异，这对AI安全和对齐领域至关重要。

5.  [Gary Marcus：生成式AI持续面临可靠性危机 - Gary Marcus](https://x.com/GaryMarcus/status/1944010211724873887)

    Gary Marcus 指出，生成式AI正面临一场“**永无止境的可靠性危机**”。该观点旨在提醒人们关注当前AI技术在稳定输出、事实准确性和可信度方面存在的根本性挑战。这表明，尽管模型能力不断增强，但其可靠性问题仍然是一个需要业界持续努力解决的核心障碍。