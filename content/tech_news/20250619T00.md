---
title: "2025.06.19.00 过去4小时全球AI发生了什么？"
date: 2025-06-19T00:00:59+08:00
categories: ["AI最新进展", "大模型", "行业动态"]
---

---

1.  [OpenAI年收入翻倍至100亿美元](https://x.com/PeterDiamandis/status/1935352337926647989)

    Peter H. Diamandis, MD 分享数据显示，OpenAI 的年收入已从 50 亿美元**翻倍增长至 100 亿美元**。目前，OpenAI 拥有 5 亿用户和 300 万付费企业，这使其有望成为全球市值最高的私人公司之一。这一显著的收入增长表明其在AI市场中的强劲表现和商业化成功。

2.  [Meta Llama 4发布新模型并推出配套课程](https://x.com/AndrewYNg/status/1935350552692658202)

    吴恩达 (Andrew Ng) 宣布与 Meta 合作推出“Building with Llama 4”短期课程。Meta 的新 **Llama 4 系列**引入了三款新模型，并采用了**专家混合 (MoE) 架构**，提高了服务效率。其中，Maverick 是一个 400B 参数模型，拥有 128 个专家和 17B 活跃参数；Scout 是一个 109B 参数模型，拥有 16 个专家和 17B 活跃参数。这两款模型支持的长上下文窗口分别高达 100 万和 1000 万 token。课程将涵盖 Llama 4 的新**多模态能力**，包括跨多图像推理和图像接地，并介绍 Llama 的**提示词优化工具**和**合成数据工具包**。

3.  [近期开放AI模型发布概览](https://x.com/mervenoyann/status/1935349636459307141)

    Merve 总结了过去一周开放AI领域发布的多个引人注目的模型。在计算机视觉和视觉语言模型 (VLM) 方面，Nanonets-OCR-s 成为了处理复选框、水印和表格的最新 OCR 模型；Meta 发布了 V-JEPA，这是视频嵌入的新 SOTA 模型；字节跳动发布了 SeedVR2-3B，一个 3B 参数的**视频修复模型**。在音频方面，Stepfun 发布了 Step-Audio-AQAA，一个大型 (137B) 音频语言模型，能够输入和生成音频。机器人领域，Nvidia 发布了 GR00T-N1.5-3B，一个新的**开放基础视觉语言动作模型**。在 3D 领域，腾讯发布了 Hunyuan3D-2.1，这是其 Hunyuan 系列的新版本，能够从文本和图像提示生成 3D 资产。

4.  [如何使用Veo3生成连贯视频教程](https://x.com/vista8/status/1935331195275112876)

    向阳乔木分享了一套基于谷歌 **Veo3** 平台的**视频生成教程**，旨在帮助用户克服小白在镜头、灯光、分镜等视频创作知识上的不足，通过“元提示词”来生成带有情节且能保持人物一致性的视频。教程详细介绍了如何利用 Gemini Deep Research 和 Claude 4 Sonnet 寻找和优化 Veo3 提示词，并指出通过 JSON 格式的元提示词能更好地控制视频生成选项。此外，还提供了使用谷歌 Flow 平台延长功能保持人物和场景一致性，以及如何使用剪映等工具对生成的多段视频进行自然拼接和增强。

5.  [Ash Vaswani团队发布24万亿tokens的丰富标注网络数据](https://x.com/ClementDelangue/status/1935322642455662790)

    Clement Delangue 转推了 Ash Vaswani 团队的最新研究，该研究**发布了 24 万亿 tokens 的丰富标注网络数据**。开发团队表示，这些数据对他们的研究工作非常有用，为AI模型的训练和发展提供了宝贵的资源。

6.  [Hugging Face PRO服务提供H200计算资源](https://x.com/ClementDelangue/status/1935307783634829328)

    Clement Delangue 转发消息称，Hugging Face PRO 现提供每月 9 美元的订阅，包含每日 25 分钟的 **H200 计算资源**（在 Spaces ZeroGPU 上）以及约 100 万免费 Token。这一服务为AI开发者提供了经济高效的访问高性能计算资源的方式，以支持模型开发和实验。