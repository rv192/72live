---
title: "2025.12.21.16 过去4小时全球AI发生了什么？"
date: 2025-12-21T16:00:08+08:00
categories: ["AI发展", "模型能力", "行业观察", "应用技巧", "未来趋势"]
---

1.  [Redis 之父 Salvatore Sanfilippo 的 AI 年终反思](https://x.com/dotey/status/2002465295047479548)

    Redis 创始人 Salvatore Sanfilippo 分享了对 AI 发展的八点深度反思。他指出，2025年“随机鹦鹉”的说法已不再被普遍接受，LLM在各项考试中表现卓越并形成内部概念表征。**思维链**被低估，它通过内部表征采样和强化学习有效提升模型表现。**可验证奖励的强化学习**打破了算力瓶颈，使模型能无限自我提升。程序员普遍接受AI辅助编程，将其视为“同事”或“独立智能体”。Transformer架构依然是通向AGI的有效路径，且思维链并未改变LLM的本质。此前反LLM的 **ARC 测试**如今也证明了LLM的抽象推理能力。最后，他警示未来20年AI的根本挑战在于**避免灭绝风险**。

2.  [Codex 正式支持 Skills 机制，解决规划模式痛点](https://x.com/dotey/status/2002420578528219306)

    Codex 近期正式引入了“Skills”机制，解决了其长期以来不支持规划（Plan）模式的痛点。现在，用户只需在 Prompt 中添加 `$plan` 即可调用内置的规划技能；对于更复杂的规划需求，还可以使用 `execplan` 功能。这一更新有望大幅提升 Codex 在复杂任务处理和自主规划方面的能力，使编程辅助工具更加智能和高效。

3.  [利用 Gemini 生成高质量信息图的实用技巧](https://x.com/dotey/status/2002414479397548045)

    有经验分享指出，使用 Gemini 生成高质量信息图时有几个关键技巧。首先，推荐使用 **Gemini 进行生成**，因为它能在出图前进行推理、提炼信息并优化提示词，从而充分发挥大语言模型的潜力。其次，模型生成图片具有随机性，需要用户进行多次尝试，即“抽卡”。最后，在获得初步满意结果后，务必进行**微调**，以确保细节达到完美效果。

4.  [AI 技术大幅缩短游戏开发周期](https://x.com/drfeifei/status/2002507216897913012)

    有团队表示，借助当前先进的 AI 技术，他们仅用 **8 周**就完成了一款游戏的开发，而这在以前可能需要 **12 个月**才能完成。这一案例突显了人工智能在加速内容创作和开发流程方面的巨大潜力，特别是在游戏开发等复杂领域，AI 正成为大幅提升效率的关键工具，有望彻底改变行业格局。

5.  [Gemini App 已集成 NotebookLM 笔记作为上下文](https://x.com/op7418/status/2002570649039221126)

    Google 的 Gemini App 现已正式支持将 NotebookLM 的笔记内容作为上下文进行引用。这项功能允许用户直接针对他们在 NotebookLM 中整理的资料、研究或个人笔记在 Gemini 中提出问题并获得更具个性化和相关性的回答。这标志着 AI 助手与个人知识管理工具的深度融合，为用户提供了更强大的信息处理能力。

6.  [NotebookLM Slides 制作指南及精细化微调策略](https://x.com/dotey/status/2002561562360656140)

    一个完整的“可编辑 NotebookLM Slides”解决方案被分享，该方案强调通过几个额外步骤实现无限的灵活性。其中一个关键技巧是利用逐张生成的方式来控制幻灯片制作，用户可以对每张幻灯片进行**精细化微调**。例如，可以要求 AI 调整文本大小、改变图标颜色等，从而迭代至像素级完美的最终效果。

7.  [微软或正在自主研发 AI 芯片](https://x.com/PeterDiamandis/status/2002521342147547492)

    有消息指出，科技巨头微软可能正在自主研发芯片。在人工智能技术飞速发展的背景下，各大公司对定制化、高性能 AI 芯片的需求日益增长。微软的这一举动，若属实，将有助于其在 AI 领域获得更强的硬件掌控力，优化其云服务和 AI 模型的运行效率，并减少对第三方芯片供应商的依赖。

8.  [大模型“出道即巅峰”后性能下降引关注](https://x.com/oran_ge/status/2002539579887530059)

    有观点指出，许多大语言模型（LLM）和生成式 AI 模型（如 GPT-4 和 Sora）似乎都经历了“出道即巅峰”的现象，即在发布初期表现惊艳，但随后其性能因**审核、量化和成本优化**等因素而出现下降。这种“降智”现象可能导致用户留存率不佳，反映出在模型能力、用户体验和运营成本之间存在持续的权衡与挑战。

9.  [AI 初创公司在巨头面前的生存策略](https://x.com/oran_ge/status/2002513784095887845)

    分析认为，当前 AI 初创公司已几乎不可能直接挑战谷歌或字节跳动等科技巨头，因为在这些巨头面前，初创公司缺乏**壁垒**。因此，初创企业更现实的生存之道是在巨头不重视或甚至鼓励的**细分领域**中寻求发展空间。虽然这可能意味着做一些巨头“看不上”或“希望你做”的事情，但这些领域仍能创造可观的利润。

10. [Ranke-4B：一个基于1913年前数据的“时光琥珀”LLM](https://x.com/dotey/status/2002498354278732130)

    Ranke-4B 是一个独特的“时光琥珀”大语言模型，其训练数据仅限于 **1913年以前**的内容。这意味着该模型能够掌握语言结构，但对世界大战、西班牙流感等现代历史事件一无所知。与这样一个“时间胶囊”般的模型探讨现代性话题，可能会产生出人意料的对话和独特的视角，为研究和应用带来有趣的可能性。

11. [对2026年AI科学领域的预测](https://x.com/mervenoyann/status/2002458039019008408)

    有预测指出，2026年将成为 **AI 在科学领域**取得重大突破的一年。诸如 Google DeepMind 和 Periodic Labs 等前沿实验室有望继续引领潮流，同时，像 CERN 这样的纯科学研究机构也将积极发布自己的 AI 模型和数据集。这一趋势预示着 AI 将在基础科学研究、数据分析和发现方面发挥越来越核心的作用，推动科学研究进入一个新时代。

12. [对未来计算机视觉和机器人技术主流化的预测](https://x.com/mervenoyann/status/2002464688005898285)

    未来的预测强调，**计算机视觉**将变得更加主流，特别是随着基础模型的发展，它们能通过视觉和文本提示实现图像分割，甚至解锁深度信息。同时，**机器人技术**也将逐步进入主流应用，尽管初期可能会面临一些挑战。这些趋势表明，AI将在感知世界和物理交互方面取得显著进展，预示着更广泛的实际应用。