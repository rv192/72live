---
title: "2025.12.21.12 过去4小时全球AI发生了什么？"
date: 2025-12-21T12:00:12+08:00
categories: ["AI进展", "大模型", "行业洞察", "应用与工具"]
---

1.  [Redis 之父 Salvatore Sanfilippo 发布 2025 年终 AI 反思：LLM 能力超预期，强化学习开启新可能](https://x.com/dotey/status/2002465295047479548)

    Redis 创始人 Salvatore Sanfilippo 分享了对 2025 年 AI 发展的八点洞察。他指出，大语言模型（LLM）的“随机鹦鹉”说法已过时，模型在各类考试中表现优异并形成内部概念表征。思维链（CoT）被低估，它通过内部表征采样和强化学习来优化推理过程。算力扩张瓶颈被可验证奖励的强化学习打破，使模型能自我提升。程序员对 AI 辅助编程的态度已从怀疑转变为接受，并出现“AI 同事”和“AI 智能体”两种主要使用模式。Sanfilippo认为Transformer架构仍有潜力，且CoT并未改变LLM的本质。此外，曾被认为LLM无法通过的ARC测试，现在顶级模型已能达到较高准确率。最后，他强调未来20年AI的根本挑战是避免灭绝，并认为LLM比许多人承认的要强大得多，但人类对其理解仍不足。

2.  [Codex 正式支持“技能（Skills）”机制，解决长期规划痛点](https://x.com/dotey/status/2002420578528219306)

    Codex 平台已正式引入“Skills”机制，解决了其长期以来不支持“Plan 模式”的痛点。现在用户只需在 Prompt 中加入 `$plan` 即可调用内置的 Plan Skill，而对于更复杂的规划需求，则可以使用 `execplan`。这一更新将大幅提升 Codex 在代码生成和任务执行方面的规划能力，使其能够更好地理解和执行多步骤的复杂指令。

3.  [利用 Gemini 生成高质量信息图的技巧](https://x.com/dotey/status/2002414479397548045)

    有经验的用户分享了使用 Gemini 生成高质量信息图的几个关键技巧：首先，**利用 Gemini 的推理能力**，因为它在生成前会进行信息提炼和提示词优化，能充分发挥大语言模型的潜力；其次，由于模型的随机性，需要**“抽卡”**，即多次尝试以获得理想结果；最后，在得到好的初步结果后，**必须进行微调**，根据需求调整细节，以达到像素级的完美。

4.  [2026 年 AI 发展预测：聚焦科学、全能模型、设备端智能和机器人](https://x.com/mervenoyann/status/2002458039019008408)

    AI 专家 Merve 预测 2026 年将是 **“AI for Science”** 的一年，Google DeepMind 将与 Periodic Labs 等独立实验室成为前沿阵地，CERN 等纯科学机构也将发布模型和数据集。此外，预测还包括：出现更小、能力更强、幻觉更少且具备推理能力的**全能（Omni）模型**；设备端的多芯片处理器（MCPs）和能控制手机的智能体（包括截屏视觉大模型）；更多的产品和用户界面创新；计算机视觉将通过视觉/文本提示的基础模型和 VLM 解决分割问题，从而实现深度感知等功能，并全面普及；机器人技术也将大规模应用。强化学习环境（如 OpenEnv）和训练即服务（如 TRL/Unsloth）将更加流行。

5.  [NotebookLM 幻灯片功能升级：实现可编辑内容与 Gemini 应用整合](https://x.com/op7418/status/2002570649039221126)

    NotebookLM 的幻灯片功能迎来重大改进，解决了此前生成的幻灯片为静态图片、无法编辑的痛点。用户现在可以通过新的工作流和提示模板，完全自定义幻灯片的文本和内容，实现逐页调整直至完美。此外，NotebookLM 的笔记已作为上下文整合到 Gemini App 中，用户可以直接针对 NotebookLM 的内容在 Gemini 中进行提问，极大提升了交互性和可用性。

6.  [AI 初创公司在巨头面前的生存挑战](https://x.com/oran_ge/status/2002513784095887845)

    当下，AI 初创公司几乎不可能直接挑战 Google 或字节跳动等科技巨头，因为巨头拥有巨大的壁垒。初创公司的生存之道在于在夹缝中寻求机会，专注于巨头们不屑或希望它们做的利基市场。尽管这是一种现实主义的考量，但通过这种方式，初创公司仍有机会获得利润并发展。

7.  [大语言模型出道即巅峰，后续普遍存在“降智”现象](https://x.com/oran_ge/status/2002539579887530059)

    有观察指出，许多大语言模型（包括 Nano Banana Pro、GPT-4 和 Sora 等）都表现出“出道即巅峰”的特性，即在发布初期展现出最佳性能，随后由于各种原因（如降本、审核、量化）导致性能下降，即所谓的“降智”现象。这种性能的不稳定性使得用户在不同阶段体验到的产品并非同一水准，从而影响了用户留存。

8.  [Ranke-4B：一个训练数据仅限于 1913 年前的“时光琥珀”LLM](https://x.com/dotey/status/2002498354278732130)

    Ranke-4B 被称为“时光琥珀 LLM”，其特别之处在于模型仅使用 1913 年之前的数据进行训练。这意味着该模型虽然学会了语言结构，但对第一次世界大战、西班牙大流感等现代历史事件一无所知。与这样一个时间胶囊般的大模型讨论现代性话题，可能会带来独特且有趣的对话体验，为研究语言和知识表征提供新视角。

9.  [Paul Graham 对年轻人的忠告：努力与好奇心是成功的关键](https://x.com/dotey/status/2002500668213387568)

    Paul Graham 给 18 岁的自己提出了三条建议：**追随好奇心而非盲目追求“成功光环”**；**辛苦努力不可或缺**，虽然不一定足够，但却是必需的；**珍惜父母的付出**。其中，前两条可概括为“努力决定你能走多远，好奇心决定你会往哪走”。这一观点得到了共鸣，许多财富自由者最终发现其追求的仍是好奇心。

10. [微软或正研发自有 AI 芯片，加速硬件布局](https://x.com/PeterDiamandis/status/2002521342147547492)

    有迹象表明，微软可能正在积极研发自己的芯片。此举若属实，将标志着微软在 AI 硬件领域的深入布局，旨在优化其 AI 模型的性能和效率，减少对第三方供应商的依赖，并在日益激烈的 AI 竞争中获得更大的控制权和竞争优势。

11. [小型团队在全球范围内实现曾需政府或大公司才能完成的工作](https://x.com/PeterDiamandis/status/2002424168608854067)

    全球范围内的小型团队正在利用新兴技术，尤其是人工智能，完成过去只有政府或大型跨国公司才能实现的工作。这一趋势体现了技术普及化和民主化的力量，使得创新和项目执行的门槛大幅降低，预示着未来创新生态的巨大变革。

12. [AI 的未来在于量子计算](https://x.com/PeterDiamandis/status/2002416656082219430)

    AI 的未来被预言与量子计算紧密相连。量子计算的超强处理能力和解决复杂问题的潜力，被认为是推动人工智能迈向新高度的关键技术。融合量子计算，AI 有望在数据分析、模拟、优化和机器学习等领域实现突破性进展。