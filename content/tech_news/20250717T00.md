---
title: "2025.07.17.00 过去4小时全球AI发生了什么？"
date: 2025-07-17T00:00:34.515+08:00
categories: ["AI最新动态", "技术发布", "行业观点"]
---

1. [Coursera联合DeepLearning.AI发布全新检索增强生成（RAG）课程 - Andrew Ng](https://x.com/AndrewYNg/status/1945502636012445937)

   吴恩达（Andrew Ng）宣布推出一门全新的Coursera课程，专注于构建**高性能、生产级的检索增强生成（RAG）系统**。该课程由DeepLearning.AI与Lamini合作创建，旨在解决LLM在处理专业、私有或最新信息时可能出现的过时或泛化问题。学员将系统学习设计和实现RAG系统的各个部分，包括检索器、向量数据库（如Weaviate）、生成和评估。课程内容还涵盖了**Agentic RAG**等前沿概念，并通过实践项目（如使用Together AI托管的开源LLM开发聊天机器人）来教授具体技能。

2. [Runway发布新一代动作捕捉模型Act-Two - 小互](https://x.com/imxiaohu/status/1945478639048589409)

   Runway公司发布了其新一代动作捕捉模型**Act-Two**。该模型实现了显著的技术提升，支持包括**微妙面部表情、肢体动作和手指在内的全身跟踪**。与前代Act-One相比，Act-Two在动作保真度、一致性和流畅性方面均有大幅改进。其核心优势在于，用户无需专业的动作捕捉服或工作室设备，仅需一个普通视频（如手机拍摄的表演）和一个参考角色图像，即可生成高质量的动作捕捉视频。

3. [如何在Colab A100上对多模态模型Gemma3n进行微调 - merve](https://x.com/mervenoyann/status/1945481841298813403)

   开发者Merve Noyan发布了一个教学性质的Colab Notebook，展示了如何利用**Google Colab A100**对多模态模型**Gemma3n**进行微调。该教程的核心是同时处理**图像、音频和文本**数据，即在带有音频的视频上进行训练。为了能在小于40GB VRAM的环境下运行，教程采用了**LoRA、音频重采样和视频降采样**等技术。这个资源为希望在多模态数据上微调模型的开发者提供了宝贵的实践指导。

4. [开源AI在降低能源消耗中的关键作用 - clem 🤗](https://x.com/ClementDelangue/status/1945477565701136475)

   Hugging Face CEO Clement Delangue提出，在关于AI能源消耗的讨论中，开源AI的作用被忽视了。他认为，如果各大前沿实验室各自**孤立地训练通用大模型**，将消耗巨大的能源。相反，推动**开源科学和开源模型**，专注于开发更小、更高效的模型，并共享大型模型，将能以一小部分能源获得更大的经济效益和竞争力。这一观点强调了协作与开放对AI可持续发展的重要性。

5. [AI在不同维度上的发展并不均衡 - Gary Marcus](https://x.com/GaryMarcus/status/1945499715803701314)

   AI专家Gary Marcus指出，AI技术的进步并非在所有维度上都是同步的。他以图像和视频生成模型为例，指出尽管从2022年的Dall-E 2到2025年的Veo 3，模型在生成**惊艳的视频**方面取得了巨大进步，但在生成**清晰、准确的文本**方面仍然存在问题，文本内容常常是乱码。这说明了在某些能力上实现规模化扩展（scaling）并不意味着所有能力都能得到同等提升。

6. [99%的美国判例法已在Hugging Face上开源 - Emad](https://x.com/EMostaque/status/1945472924342710618)

   Enrico Shippole宣布，他们已将**99%的美国判例法**在Hugging Face上开源。他指出，这些数据此前被许多AI和法律科技公司高价出售。此次开源行动极大地推动了法律数据的民主化，为研究人员、开发者和初创企业提供了宝贵的资源，可能将**加速法律科技领域的创新**和应用开发，降低相关技术门槛。