---
title: "2025.10.19.08 过去4小时全球AI发生了什么？"
date: 2025-10-19T08:00:14+08:00
categories: ["AI发展", "LLM", "AGI", "研究", "产业评论"]
---

1.  [Andrej Karpathy 深入解读 Dwarkesh 播客谈话要点：AGI 时间表、AI 学习范式与智能体设计-Andrej Karpathy](https://x.com/karpathy/status/1979644538185752935)

    Andrej Karpathy 在其 Dwarkesh 播客后的补充说明中，详细阐述了对 AI 领域多个关键议题的看法。他认为 **AGI 实现的“十年时间表”**相对当前炒作而言显得悲观，但与AI怀疑论者相比仍乐观，强调LLM进步巨大但仍有大量集成和安全工作待完成。Karpathy 区分了 **“动物式”学习**（进化预装智能）和 **“幽灵式”LLM 智能**（通过预测下一个词预装智能），并提出应使 AI 更像动物。他对 **强化学习（RL）**持短期看空态度，认为其效率低且噪声大，转而看好“智能体式互动”和“系统提示词学习”等新的学习范式。对于 **LLM 智能体**，他批评业界“过度设计”超越现有能力，倡导与 AI **协作**而非完全自主，强调任务应分解为人类可理解的小块，让 AI 解释代码、证明正确性，并主动提问，以促使人类程序员共同进步，避免生成大量“烂代码”。

2.  [GPT-5 数学能力争议：OpenAI “解出” Erdős 难题真相揭示-宝玉](https://x.com/dotey/status/1979640848041071097)

    OpenAI 研究员 Mark Sellke 高调宣布 GPT-5 “找到”10个著名的厄尔多斯数学难题的解法，引发广泛关注，一度被误认为 GPT-5 独立破解了难题。然而，谷歌 DeepMind CEO Demis Hassabis 随后质疑，指出 GPT-5 只是通过网络搜索 **检索到现有文献中早已存在的解决方案**，而非自主解决。erdosproblems.com 网站的维护者 Thomas Bloom 也证实，网站上的“未解”状态仅表示他个人未发现相关论文，不代表全球数学界没有解决方案。OpenAI 研究员 Sebastien Bubeck 随后删除了原推文并道歉，澄清 GPT-5 仅是发现了已发表的文献解法。Yann LeCun 对此评论为“被自己吹嘘GPT的言论坑惨了”。这一事件凸显了 AI 在文献检索方面的强大能力，但也暴露出部分研究人员在宣传时可能存在的 **夸大和误导性表述**问题。

3.  [AI 记忆系统的新思考：从 RAG 到认知与策略存储-orange.ai](https://x.com/oran_ge/status/1979676189414576535)

    针对 AK 之前关于人类学习和记忆的观点，有评论指出当前许多基于 RAG（检索增强生成）的 AI 记忆项目在召回机制上存在不足，常常“胡乱召回”，缺乏场景适配和相关性。随着 **Claude Code 的文件上下文功能**和 **Skills 的发布**，AI 记忆系统正变得更加清晰。该观点认为，对于 AI 而言，相比存储个人偏好和生活细节的记忆，**解决问题的认知和策略性记忆**更具价值。这与 AK 提出的“系统提示词变化”的学习过程相呼应，即 AI 通过思考得出结论并以明确方式“记住”，用于保存通用的问题解决知识，而非随机事实，将其比作《记忆碎片》中尚未配备备忘录的主人公。

4.  [对 OpenAI AgenKit 的看法：技术方向的灵活性与追随性-宝玉](https://x.com/dotey/status/1979644898799431943)

    针对 OpenAI 推出 AgenKit，有评论认为这不代表 OpenAI 将铁定沿着该方向发展。如果市场上出现更好的解决方案，例如 **“Skills”等技术范式**，OpenAI 能够迅速跟进并采纳，最多只是换个名字重新包装。评论指出，OpenAI 历史上曾多次采纳或优化其他公司或研究者提出的概念，例如 **ChatGPT Project 和 Codex**，甚至对 **MCP（Multi-modal Coherence Pre-training）**等技术也支持良好。这表明 OpenAI 在技术路线选择上保持高度灵活性和快速迭代能力，擅长吸收和整合现有创新，而非固守单一路径。