---
title: "2025.06.23.04 过去4小时全球AI发生了什么？"
date: 2025-06-23T04:00:59+08:00
categories: ["AI新闻", "技术更新", "政策与伦理", "开发实践"]
---

---

1.  [美国政府将推出AI驱动平台 - Peter H. Diamandis, MD](https://x.com/PeterDiamandis/status/1936854345212989900)

    Peter H. Diamandis透露，美国计划在7月4日左右推出一个新平台，旨在将联邦机构转变为**AI驱动**的实体。这一举措预示着美国政府将迈向AI优先的运作模式。此举引发了对公民是否已为这种变革做好准备的讨论。尽管具体平台名称在原文中显示为缩短链接，但明确指出其目标是将AI深度融入政府服务和职能中。

2.  [LLM的危险性：不诚实、不可预测且潜在危险 - Gary Marcus](https://x.com/GaryMarcus/status/1936853817213231396)

    知名AI研究者Gary Marcus在其“Marcus on AI”新文章中，再次强调了**大型语言模型（LLMs）的固有风险**。他将LLMs描述为“不诚实、不可预测且潜在危险”的工具，并引用霍布斯对生物生命的描述来类比其缺陷。Marcus的文章深入探讨了如何应对这些挑战，呼吁关注LLMs的可靠性和安全性问题，以避免其可能带来的负面影响。

3.  [Hugging Face发布Deepsite v2 - clem 🤗](https://x.com/ClementDelangue/status/1936848524186095722)

    Hugging Face近期发布了**Deepsite v2**，这是其开源**“情绪编码平台”（vibe coding platform）**的全面升级版本。尽管原推文内容有所截断，但明确指出新版本带来了显著改进。Deepsite v2的发布标志着Hugging Face在推动开源AI工具和平台方面的又一进展，旨在为开发者提供更强大的情绪识别和处理能力，进一步丰富了AI生态系统。

4.  [AI前沿：让模型认知其“不懂” - Gary Marcus](https://x.com/GaryMarcus/status/1936844631951704393)

    Gary Marcus转发Ramez的观点，指出当前AI领域的一个重要前沿是让模型能够**识别自己“不懂”的知识边界**，并据此调整行为。这强调了**AI透明度**和**可靠性**的重要性，即模型不仅需要提供答案，也需要能力指出其知识局限性。实现这一目标对于构建更安全、更可信赖的AI系统至关重要，有助于减少AI“幻觉”现象的发生。

5.  [美国国家科学基金会（NSF）预算大幅削减 - Gary Marcus](https://x.com/GaryMarcus/status/1936843854390698496)

    Gary Marcus转发了关于美国国家科学基金会（**NSF**）**2026财年预算请求将大幅削减**50%的消息。这一提议的削减对科学研究，尤其是对AI等前沿领域的**基础研究 funding** 构成严峻挑战。削减可能严重影响未来的科研创新和人才培养，引发了对美国在科技领域竞争力的担忧。

6.  [Claude Code 上下文控制最佳实践 - 宝玉](https://x.com/dotey/status/1936834470306529688)

    开发者宝玉（@dotey）分享了使用**Claude Code**等**AI代码助手**时的**上下文管理最佳实践**。他建议，为确保代码生成质量和检索效率，应**将AI工具限定在特定项目目录**（如前端或后端），以避免混淆和不相关代码的干扰。对于跨端协作，他建议将任务分解，先生成共享文档再引用，强调**由开发者主动引导AI上下文**，而非完全依赖AI自动处理，这既能提升结果准确性又能节省Tokens成本。